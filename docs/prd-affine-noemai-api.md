# PRD ‚Äì AFFiNE API Extensions for NoemAI

| Champ | D√©tail |
| --- | --- |
| Auteur | Claude Code (Gap Analysis 2025-01-19) |
| Date | 2025-01-19 |
| Statut | Ready for Implementation |
| Projet | `projects/notebooks_api` |
| Contexte | Am√©liorations API pour projet NoemAI (Partenaire Cognitif Augment√©) |
| Version | 1.2 |

---

## 0. Executive Summary

Le projet **NoemAI** vise √† cr√©er un partenaire cognitif augment√© qui utilise AFFiNE comme canvas collaboratif pour la r√©flexion en temps r√©el. L'analyse de faisabilit√© r√©v√®le que **70% des besoins sont d√©j√† couverts** par l'API Affine actuelle, mais n√©cessite des extensions sp√©cifiques pour supporter :

1. **Brush elements** (strokes manuscrits) - CRUD complet + feedback visuel
2. **Canvas screenshots** - Capture multi-r√©solution progressive (fit-all/viewport/region)
3. **Transformation assist√©e IA** - Brush ‚Üí √âl√©ments vectoriels

**Innovations Cl√©s** :
- üé® **Highlight Brush** : LLM peut changer les couleurs pour feedback visuel temps r√©el
- üì∏ **Progressive Screenshot** : fit-all ‚Üí analyse LLM ‚Üí screenshots cibl√©s HD (30x moins cher, 5x plus rapide)

**Impact estim√©** : R√©duction de 10 semaines (2.5 mois) du time-to-market NoemAI en √©liminant le besoin de d√©velopper un client custom.

**Priorit√© Business** : Haute - Permet √† NoemAI d'utiliser AFFiNE comme plateforme universelle (tablettes, desktop, mobile).

---

## 1. Contexte

### 1.1 Projet NoemAI

**Vision** : Syst√®me d'augmentation cognitive en temps r√©el agissant comme "sparring partner" de r√©flexion.

**Architecture cible** :
```
Tablettes (Onyx Boox / iPad)
  ‚Üí AFFiNE Web UI (capture ink native)
  ‚Üí AFFiNE Server (stockage Y.js)
  ‚Üí NoemAI Processor (analyse IA + transformation)
  ‚Üí Claude Vision API (compr√©hension s√©mantique)
```

**Use Cases Cl√©s** :
1. **R√©flexion Solo** : Utilisateur dessine/√©crit ‚Üí IA structure en mindmap
2. **War Room** : √âquipe brainstorme ‚Üí IA d√©tecte patterns et sugg√®re connexions
3. **Transformation Brush** : Strokes manuscrits ‚Üí Shapes/Connectors propres

### 1.2 Gap Analysis (2025-01-19)

| Fonctionnalit√© NoemAI | Couverture API Affine | Gap |
|----------------------|---------------------|-----|
| Canvas collaboratif ‚úÖ | 100% - Edgeless natif | Aucun |
| Synchronisation temps r√©el ‚úÖ | 100% - Y.js CRDT | Aucun |
| Recherche s√©mantique ‚úÖ | 100% - Copilot API | Aucun |
| Capture ink (lecture) ‚úÖ | 100% - Brush elements | Aucun |
| Capture ink (cr√©ation) ‚ö†Ô∏è | 0% - Type non support√© | **Ajouter support** |
| Screenshot canvas ‚ùå | 0% - Pas d'endpoint | **Cr√©er endpoint** |
| Transformation IA ‚ö†Ô∏è | 50% - CRUD manuel | **Ajouter helpers** |
| Audio (capture/transcription) ‚ùå | 0% - Hors scope | Externe (Web Audio API) |
| Graphe de connaissance ‚ö†Ô∏è | 30% - Linked docs | Externe (Neo4j) |

**Verdict** : Architecture AFFiNE Pure = **VIABLE** avec 3-4 extensions mineures.

---

## 2. Objectifs

### 2.1 Objectifs Business

1. **Acc√©l√©rer NoemAI** : R√©duire time-to-market de 22-28 semaines ‚Üí 14-18 semaines (-40%)
2. **Universalit√© Hardware** : Support Onyx Boox, iPad, Surface, Desktop (m√™me codebase)
3. **Contribution Open Source** : Extensions r√©utilisables pour la communaut√© AFFiNE

### 2.2 Objectifs Techniques

1. **Brush CRUD Complet** : Support cr√©ation/modification brush elements via API
2. **Canvas Rendering** : Endpoint pour capturer screenshot du canvas
3. **Transformation Assist√©e** : Helpers pour workflow Brush ‚Üí Vectoriel
4. **Documentation** : Patterns NoemAI int√©gr√©s dans `docs/`

### 2.3 Non-Objectifs

- ‚ùå Audio capture/transcription (g√©r√© par NoemAI Processor externe)
- ‚ùå OCR manuscrit (g√©r√© par services tiers : Google Vision, Tesseract)
- ‚ùå Graphe de connaissance (g√©r√© par Neo4j externe)
- ‚ùå Client mobile custom (utiliser AFFiNE web natif)

---

## 3. √âtat Actuel

### 3.1 Brush Elements - Analyse Compl√®te

**Format Existant** (5184 brush d√©tect√©s dans `Tests/API Test Folder/Test-SketchAPI`) :

```json
{
  "id": "WmOqm648GY",
  "type": "brush",
  "lineWidth": 4,
  "color": {
    "dark": "#ffffff",
    "light": "#000000"
  },
  "points": [
    [2, 256.90234375, 0.072021484375],        // [x, y, pressure]
    [11.9951171875, 231.912109375, 0.185302734375],
    // ... 28 autres points
  ],
  "xywh": "[-3679.148,-82.461,123.951,278.893]",  // Bounding box
  "rotate": 0,
  "index": "a1",
  "seed": 330644115
}
```

**Support Actuel** :

| Op√©ration | Status | Endpoint | Notes |
|-----------|--------|----------|-------|
| **GET** (Liste) | ‚úÖ Fonctionnel | `GET /workspaces/:wId/documents/:dId/edgeless` | Retourne tous √©l√©ments (shape, connector, text, brush) |
| **POST** (Cr√©er) | ‚ùå Non support√© | `POST .../edgeless/elements` | Erreur : `"Unknown element type: brush"` |
| **PATCH** (Modifier) | ‚ö†Ô∏è Non test√© | `PATCH .../edgeless/elements/:eId` | Probablement fonctionnel si cr√©ation OK |
| **DELETE** (Supprimer) | ‚úÖ Probablement OK | `DELETE .../edgeless/elements/:eId` | M√©thode g√©n√©rique `deleteElement()` |

**Code Source Concern√©** :
- `src/client/types/edgeless.ts:12` - Type `EdgelessElementType` (manque `'brush'`)
- `src/client/runtime/element-defaults.ts:158` - Fonction `applyElementDefaults()` (manque case `'brush'`)
- `src/client/runtime/affine-client.ts:1655` - M√©thode `getEdgelessElements()` ‚úÖ OK

### 3.2 Canvas Screenshot - Non Existant

**Besoin** : Capturer le canvas Edgeless en image (PNG/JPEG) pour analyse IA.

**Status** : ‚ùå Aucun endpoint disponible

**Approches Possibles** :
1. **Server-side rendering** (headless browser - complexe)
2. **Client-side capture** (HTML Canvas API - pr√©f√©r√© si possible)
3. **Reconstruction SVG** (depuis √©l√©ments Yjs - tr√®s complexe)

**D√©cision Recommand√©e** : √âtudier faisabilit√© server-side rendering via Playwright/Puppeteer.

---

## 4. Exigences Fonctionnelles

### 4.1 Priority 1 : Brush CRUD Complet

#### 4.1.1 Support Cr√©ation Brush

**Endpoint** : `POST /workspaces/:workspaceId/documents/:docId/edgeless/elements`

**Payload** :
```json
{
  "type": "brush",
  "points": [
    [100, 100, 0.5],
    [150, 120, 0.7],
    [200, 100, 0.9],
    [250, 80, 1.0],
    [300, 100, 0.8]
  ],
  "lineWidth": 6,
  "color": {
    "dark": "#ff0000",
    "light": "#ff0000"
  },
  "rotate": 0
}
```

**Response** :
```json
{
  "id": "abc123xyz",
  "type": "brush",
  "index": "a1",
  "seed": 1234567890,
  "lineWidth": 6,
  "color": {"dark": "#ff0000", "light": "#ff0000"},
  "points": [[100,100,0.5], [150,120,0.7], ...],
  "xywh": [100,80,200,40],
  "rotate": 0
}
```

**Comportements Requis** :
- ‚úÖ Calculer `xywh` automatiquement depuis `points` si non fourni
- ‚úÖ G√©n√©rer `index` (z-order) automatiquement
- ‚úÖ G√©n√©rer `seed` al√©atoire si non fourni
- ‚úÖ Valider `points` : minimum 2 points, format `[x, y, pressure]`

#### 4.1.2 Support Modification Brush

**Endpoint** : `PATCH /workspaces/:workspaceId/documents/:docId/edgeless/elements/:elementId`

**Payload** (modification partielle) :
```json
{
  "lineWidth": 8,
  "color": {"dark": "#00ff00", "light": "#00ff00"}
}
```

**Comportements** :
- ‚úÖ Modifier uniquement les propri√©t√©s fournies
- ‚úÖ Recalculer `xywh` si `points` modifi√©s

#### 4.1.3 Cas d'Usage : Feedback Visuel pour LLM ‚≠ê NOUVEAU

**Contexte** : Le LLM doit pouvoir mettre en √©vidence les brush pendant l'analyse progressive pour cr√©er un feedback visuel temps r√©el.

**Tool LLM** : `highlight_brush(brushIds, color, reason)`

**Impl√©mentation** : Simple PATCH de la propri√©t√© `color` des brush cibl√©s.

**Exemple - Workflow d'Analyse Progressive** :
```typescript
// LLM d√©marre analyse
await client.updateEdgelessElement(workspaceId, docId, "brush-1", {
  color: { dark: "#FFD700", light: "#FFD700" } // Jaune = analyzing
});

// Screenshot r√©gion cibl√©e
const screenshot = await captureRegion(x, y, width, height);

// Analyse termin√©e ‚Üí Marquer vert
await client.updateEdgelessElement(workspaceId, docId, "brush-1", {
  color: { dark: "#00FF00", light: "#00FF00" } // Vert = processed
});

// Brush √† transformer ‚Üí Marquer rouge
await client.updateEdgelessElement(workspaceId, docId, "brush-2", {
  color: { dark: "#FF0000", light: "#FF0000" } // Rouge = target
});

// Brush hors scope ‚Üí Marquer gris
await client.updateEdgelessElement(workspaceId, docId, "brush-3", {
  color: { dark: "#808080", light: "#808080" } // Gris = ignore
});
```

**Helper Recommand√©** (√† ajouter dans `affine-client.ts`) :
```typescript
/**
 * Change la couleur d'un ou plusieurs brush pour feedback visuel.
 * Support presets : 'analyzing', 'processed', 'target', 'ignore'
 */
async highlightBrush(
  workspaceId: string,
  docId: string,
  brushIds: string[],
  colorPreset: 'analyzing' | 'processed' | 'target' | 'ignore' | string
): Promise<void> {
  const colorMap = {
    analyzing: '#FFD700',  // Jaune
    processed: '#00FF00',  // Vert
    target: '#FF0000',     // Rouge
    ignore: '#808080'      // Gris
  };

  const color = colorMap[colorPreset] || colorPreset;
  const colorObj = { dark: color, light: color };

  // Batch update
  await Promise.all(
    brushIds.map(id =>
      this.updateEdgelessElement(workspaceId, docId, id, { color: colorObj })
    )
  );
}
```

**Avantages** :
- üéØ Feedback visuel temps r√©el pour l'utilisateur
- üêõ Debugging facilit√© (voir o√π le LLM bloque)
- ü§ù Collaboration War Room (√©quipe voit les zones trait√©es)
- üîÑ Workflow it√©ratif (corriger avant transformation finale)

#### 4.1.4 Tests Requis

**Test Suite** : `tests/unit/brush-elements.test.ts`

1. **Test cr√©ation basique** : Cr√©er brush avec 5 points ‚Üí V√©rifier ID retourn√©
2. **Test calcul xywh** : Cr√©er brush sans xywh ‚Üí V√©rifier bounding box calcul√©e
3. **Test modification** : Modifier lineWidth ‚Üí V√©rifier propri√©t√© mise √† jour
4. **Test suppression** : Supprimer brush ‚Üí V√©rifier GET ne le retourne plus
5. **Test validation** : Cr√©er brush avec 1 point ‚Üí Erreur 400
6. **Test validation** : Cr√©er brush avec points invalides ‚Üí Erreur 400
7. **Test highlight** : Modifier couleur brush ‚Üí V√©rifier couleur mise √† jour ‚≠ê NOUVEAU
8. **Test highlight batch** : Modifier couleur 10 brush simultan√©ment ‚Üí V√©rifier toutes les couleurs ‚≠ê NOUVEAU

**Smoke Test** : `scripts/run-brush-api-smoke.ts`
- Cr√©er brush programmatiquement dans `Tests/API Test Folder`
- Lire via GET
- Modifier
- Supprimer
- V√©rifier cleanup

### 4.2 Priority 2 : Canvas Screenshot API ‚≠ê‚≠ê APPROCHE PROGRESSIVE

#### 4.2.1 Vision : Multi-R√©solution Orchestr√©e par LLM

**Concept Cl√©** : Au lieu de capturer un screenshot massif haute r√©solution du canvas complet, l'API supporte **3 modes de cadrage** permettant une approche progressive :

1. **`fit-all`** : Vue d'ensemble (basse r√©solution acceptable) - LLM analyse la structure globale
2. **`viewport`** : Vue utilisateur actuelle (avec zoom/pan)
3. **`region`** : Zoom cibl√© haute r√©solution sur zones sp√©cifiques - LLM demande des d√©tails

**Workflow Intelligent** :
```
Phase 1 : Screenshot fit-all (1920x1080)
   ‚Üì
LLM analyse ‚Üí Identifie 3 zones d'int√©r√™t
   ‚Üì
Phase 2 : Screenshots cibl√©s haute r√©solution (3x 1920x1080)
   ‚Üì
LLM transformation pr√©cise avec correspondance brush
```

**Avantages vs Approche Na√Øve** :
- üí∞ **30x moins cher** : $0.45 vs $15 (3 images cibl√©es vs 1 image 10Kx8K)
- ‚ö° **5x plus rapide** : 8s vs 40s
- üéØ **Plus pr√©cis** : Haute r√©solution uniquement o√π n√©cessaire
- üß† **Adaptatif** : LLM d√©cide o√π zoomer selon complexit√©

#### 4.2.2 Endpoint Screenshot Multi-Mode

**Endpoint** : `GET /workspaces/:workspaceId/documents/:docId/edgeless/screenshot`

**Query Parameters** :

**Mode de cadrage** :
- `mode` (optional) : `viewport` | `fit-all` | `region` (d√©faut: `fit-all`)

**Pour mode `viewport`** :
- `zoom` (optional) : Niveau de zoom (0.5 = 50%, 1 = 100%, 2 = 200%)
- `centerX` (optional) : Coordonn√©e X du centre visible
- `centerY` (optional) : Coordonn√©e Y du centre visible

**Pour mode `region`** (‚≠ê Principal pour NoemAI) :
- `x` (required) : Coordonn√©e X canvas du coin sup√©rieur gauche
- `y` (required) : Coordonn√©e Y canvas du coin sup√©rieur gauche
- `regionWidth` (required) : Largeur de la zone √† capturer (coordonn√©es canvas)
- `regionHeight` (required) : Hauteur de la zone √† capturer

**R√©solution sortie** (tous modes) :
- `width` (optional) : Largeur image en pixels (d√©faut: 1920)
- `height` (optional) : Hauteur image en pixels (d√©faut: 1080)
- `format` (optional) : `png` | `jpeg` (d√©faut: `png`)
- `quality` (optional) : 1-100 pour JPEG (d√©faut: 90)

**Response** :
- `Content-Type: image/png` ou `image/jpeg`
- Body : Image binaire

**Exemples d'Usage** :

```bash
# Mode 1 : Vue d'ensemble (analyse globale)
curl "https://affine-api.robotsinlove.be/workspaces/ABC/documents/XYZ/edgeless/screenshot?mode=fit-all&width=1920&height=1080" \
  -o canvas-overview.png

# Mode 2 : Viewport utilisateur (contexte actuel)
curl "https://affine-api.robotsinlove.be/workspaces/ABC/documents/XYZ/edgeless/screenshot?mode=viewport&zoom=1&centerX=0&centerY=0" \
  -o canvas-viewport.png

# Mode 3 : R√©gion sp√©cifique haute r√©solution (zoom cibl√© LLM)
curl "https://affine-api.robotsinlove.be/workspaces/ABC/documents/XYZ/edgeless/screenshot?mode=region&x=-3500&y=-100&regionWidth=1000&regionHeight=800&width=1920&height=1080" \
  -o canvas-region-A.png
```

#### 4.2.3 Cas d'Usage NoemAI : Transformation Progressive

**Architecture avec LLM Tool Calling** :

```typescript
// LLM dispose de 2 tools
const tools = [
  {
    name: "capture_region",
    description: "Capture screenshot haute r√©solution d'une r√©gion sp√©cifique. Utilise quand besoin de plus de d√©tails.",
    input_schema: {
      type: "object",
      properties: {
        x: { type: "number", description: "Coordonn√©e X canvas" },
        y: { type: "number", description: "Coordonn√©e Y canvas" },
        width: { type: "number", description: "Largeur zone" },
        height: { type: "number", description: "Hauteur zone" },
        reason: { type: "string", description: "Pourquoi cette zone est int√©ressante" }
      },
      required: ["x", "y", "width", "height"]
    }
  },
  {
    name: "create_vectorial_element",
    description: "Cr√©e √©l√©ment vectoriel pour remplacer brush manuscrits.",
    input_schema: {
      type: "object",
      properties: {
        type: { type: "string", enum: ["shape", "connector", "text", "mindmap"] },
        x: { type: "number" },
        y: { type: "number" },
        width: { type: "number" },
        height: { type: "number" },
        brushIds: { type: "array", items: { type: "string" } }
      }
    }
  },
  {
    name: "highlight_brush",
    description: "Change la couleur d'un ou plusieurs brush pour feedback visuel (analyse en cours, d√©j√† trait√©, √† ignorer).",
    input_schema: {
      type: "object",
      properties: {
        brushIds: { type: "array", items: { type: "string" }, description: "IDs des brush √† mettre en √©vidence" },
        color: { type: "string", description: "Couleur (#RRGGBB ou preset: 'analyzing', 'processed', 'ignore', 'target')" },
        reason: { type: "string", description: "Pourquoi cette mise en √©vidence" }
      },
      required: ["brushIds", "color"]
    }
  }
];

// Workflow progressif
async function transformBrushToVectorial(workspaceId: string, docId: string) {
  // 1. Vue globale (fit-all, basse r√©solution OK)
  const globalScreenshot = await fetch(
    `${API_URL}/workspaces/${workspaceId}/documents/${docId}/edgeless/screenshot?mode=fit-all&width=1280&height=720`
  );

  // 2. LLM analyse + fournir m√©tadonn√©es brush
  const brushMetadata = await affineClient.getEdgelessElements(workspaceId, docId)
    .then(els => els.filter(el => el.type === 'brush').map(b => ({ id: b.id, xywh: b.xywh })));

  const response = await claudeAPI.messages.create({
    model: "claude-3-5-sonnet-20241022",
    max_tokens: 4096,
    tools,
    messages: [{
      role: "user",
      content: [
        { type: "image", source: { type: "base64", media_type: "image/png", data: globalImage } },
        {
          type: "text",
          text: `Analyse ce canvas. M√©tadonn√©es brush : ${JSON.stringify(brushMetadata)}

          Si besoin de d√©tails, utilise capture_region. Une fois pr√™t, utilise create_vectorial_element.`
        }
      ]
    }]
  });

  // 3. LLM utilise les tools (capture_region + create_vectorial_element)
  // 4. Transformation automatique
}
```

**Exemple de Conversation LLM avec Feedback Visuel** :

```
Tour 1 (fit-all) :
  LLM: "Je vois 3 zones : mindmap (gauche), flowchart (droite), notes (bas).
        Le mindmap est flou, je zoome."
  ‚Üí highlight_brush(brushIds=["brush-1", "brush-2", ...], color="analyzing", reason="Zone mindmap en cours d'analyse")
  ‚Üí capture_region(x=-3500, y=-200, width=1000, height=800, reason="Analyser mindmap")

Tour 2 (r√©gion mindmap HD) :
  LLM: "Mindmap clair : 'Projet NoemAI' au centre, 3 branches.
        Je marque comme trait√© et v√©rifie le flowchart."
  ‚Üí highlight_brush(brushIds=["brush-1", "brush-2", ...], color="processed", reason="Mindmap analys√©")
  ‚Üí highlight_brush(brushIds=["brush-10", "brush-11", ...], color="analyzing", reason="Zone flowchart en analyse")
  ‚Üí capture_region(x=-1500, y=-100, width=1000, height=600, reason="Analyser flowchart")

Tour 3 (r√©gion flowchart HD) :
  LLM: "Flowchart : Start ‚Üí Capture ‚Üí Analyze ‚Üí Transform ‚Üí End.
        Les notes en bas semblent hors scope, je les marque en gris."
  ‚Üí highlight_brush(brushIds=["brush-10", "brush-11", ...], color="target", reason="Flowchart √† transformer")
  ‚Üí highlight_brush(brushIds=["brush-20", "brush-21", ...], color="ignore", reason="Notes hors scope")
  ‚Üí create_vectorial_element(type="mindmap", x=-3500, y=-200, width=1000, height=800, brushIds=["brush-1", "brush-2", ...])
  ‚Üí create_vectorial_element(type="shape", x=-1500, y=-100, width=200, height=100, brushIds=["brush-10", "brush-11", ...])
```

**Patterns de Couleurs Recommand√©s** :

| Preset | Couleur | Usage | Exemple |
|--------|---------|-------|---------|
| `analyzing` | Jaune (`#FFD700`) | Zone en cours d'analyse par le LLM | "Je zoome sur cette zone" |
| `processed` | Vert (`#00FF00`) | Brush d√©j√† analys√© et trait√© | "Mindmap compris, pass√© au flowchart" |
| `target` | Rouge (`#FF0000`) | Brush cibl√© pour transformation | "Ces brush vont devenir des shapes" |
| `ignore` | Gris (`#808080`) | Brush hors scope ou √† ignorer | "Notes non structur√©es, on garde en l'√©tat" |

**Avantages Feedback Visuel** :
- üéØ **UX am√©lior√©e** : L'utilisateur voit en temps r√©el ce que le LLM analyse
- üîç **Debugging** : Facile de comprendre o√π le LLM a des difficult√©s
- ü§ù **Collaboration** : En mode War Room, l'√©quipe voit les zones trait√©es
- üîÑ **It√©ratif** : L'utilisateur peut corriger avant transformation finale
```

#### 4.2.4 Impl√©mentation Technique (Playwright)

**Approche Server-Side Rendering** ‚≠ê RECOMMAND√â

```typescript
import { chromium } from 'playwright';

interface CaptureOptions {
  mode: 'viewport' | 'fit-all' | 'region';
  outputSize: { width: number; height: number };
  viewport?: { zoom: number; centerX: number; centerY: number };
  region?: { x: number; y: number; width: number; height: number };
}

async function captureCanvas(
  workspaceId: string,
  docId: string,
  options: CaptureOptions
): Promise<Buffer> {
  const browser = await chromium.launch({ headless: true });
  const page = await browser.newPage({
    viewport: { width: options.outputSize.width, height: options.outputSize.height }
  });

  await page.goto(
    `https://affine.robotsinlove.be/workspace/${workspaceId}/${docId}?mode=edgeless`,
    { waitUntil: 'networkidle' }
  );

  await page.waitForSelector('.affine-edgeless-surface', { timeout: 10000 });

  // Configuration selon le mode
  if (options.mode === 'fit-all') {
    // Calculer bounds de tous les √©l√©ments
    const allElements = await getEdgelessElements(workspaceId, docId);
    const bounds = calculateGlobalBounds(allElements);

    await page.evaluate((bounds) => {
      const edgeless = document.querySelector('.affine-edgeless-root');
      if (edgeless?.viewport) {
        const centerX = bounds.x + bounds.width / 2;
        const centerY = bounds.y + bounds.height / 2;
        const zoom = Math.min(
          window.innerWidth / bounds.width,
          window.innerHeight / bounds.height
        );
        edgeless.viewport.setCenter(centerX, centerY);
        edgeless.viewport.setZoom(zoom);
      }
    }, bounds);

  } else if (options.mode === 'region' && options.region) {
    // Cadrer sur r√©gion sp√©cifique
    await page.evaluate((region, outputSize) => {
      const edgeless = document.querySelector('.affine-edgeless-root');
      if (edgeless?.viewport) {
        const centerX = region.x + region.width / 2;
        const centerY = region.y + region.height / 2;
        const zoom = Math.min(
          outputSize.width / region.width,
          outputSize.height / region.height
        );
        edgeless.viewport.setCenter(centerX, centerY);
        edgeless.viewport.setZoom(zoom);
      }
    }, options.region, options.outputSize);

  } else if (options.mode === 'viewport' && options.viewport) {
    // Restaurer viewport utilisateur
    await page.evaluate((vp) => {
      const edgeless = document.querySelector('.affine-edgeless-root');
      if (edgeless?.viewport) {
        edgeless.viewport.setCenter(vp.centerX, vp.centerY);
        edgeless.viewport.setZoom(vp.zoom);
      }
    }, options.viewport);
  }

  await page.waitForTimeout(500); // Stabilisation

  const screenshot = await page.screenshot({ type: 'png' });
  await browser.close();

  return Buffer.from(screenshot);
}
```

**Avantages Playwright** :
- ‚úÖ Rendu identique √† l'UI utilisateur
- ‚úÖ Support CSS/Th√®mes automatique
- ‚úÖ Gestion viewport/zoom native

**Inconv√©nients** :
- ‚ö†Ô∏è N√©cessite Playwright install√©
- ‚ö†Ô∏è Overhead lancement browser (~2s)
- ‚ö†Ô∏è Complexit√© d√©ploiement (headless Chrome)

**Optimisations** :
1. **Cache screenshots** (TTL 30s) : Si LLM redemande m√™me screenshot
2. **R√©solution adaptative** : fit-all en 1280x720, region en 1920x1080
3. **Batch screenshots** : Capturer plusieurs r√©gions avec 1 seul browser launch

#### 4.2.3 Tests Requis

**Test Suite** : `tests/unit/canvas-screenshot.test.ts`

1. **Test capture basique** : Screenshot document vide ‚Üí Image 1920x1080
2. **Test avec √©l√©ments** : Cr√©er 3 shapes ‚Üí Screenshot contient les formes
3. **Test r√©solution** : width=800, height=600 ‚Üí Image aux bonnes dimensions
4. **Test format JPEG** : format=jpeg, quality=80 ‚Üí Image JPEG valide
5. **Test viewport** : viewport=[100,100,500,500] ‚Üí Capture zone sp√©cifique

**Smoke Test** : `scripts/run-screenshot-smoke.ts`
- Cr√©er document avec 5 shapes color√©es
- Capturer screenshot
- Sauvegarder `/tmp/canvas-test.png`
- V√©rifier taille fichier > 10KB

### 4.3 Priority 3 : Transformation Assist√©e (Helpers)

#### 4.3.1 Helper : Bounding Box Matching

**M√©thode** : `AffineClient.matchBrushByBoundingBox()`

```typescript
interface BoundingBox {
  x: number;
  y: number;
  width: number;
  height: number;
}

async matchBrushByBoundingBox(
  workspaceId: string,
  docId: string,
  targetBox: BoundingBox
): Promise<BrushElement[]> {
  // R√©cup√®re tous les brush qui chevauchent la zone cible
}
```

**Cas d'Usage** :
```typescript
// IA a d√©tect√© un rectangle √† [100, 200, 150, 100]
const detectedBox = { x: 100, y: 200, width: 150, height: 100 };

// Trouver les brush correspondants
const matchingBrush = await client.matchBrushByBoundingBox(
  workspaceId,
  docId,
  detectedBox
);

// Supprimer les brush
for (const brush of matchingBrush) {
  await client.deleteEdgelessElement(workspaceId, docId, brush.id);
}

// Cr√©er shape propre
await client.createEdgelessElement(workspaceId, docId, {
  type: 'shape',
  shapeType: 'rect',
  xywh: [detectedBox.x, detectedBox.y, detectedBox.width, detectedBox.height]
});
```

#### 4.3.2 Module NoemAI (Exemple d'Int√©gration)

**Fichier** : `src/noemai/brush-transformer.ts` (documentation r√©f√©rence)

```typescript
import { AffineClient } from '../client/index.js';
import Anthropic from '@anthropic-ai/sdk';

export class NoemAIBrushTransformer {
  constructor(
    private affineClient: AffineClient,
    private claudeAPI: Anthropic
  ) {}

  /**
   * Transforme les brush manuscrits en √©l√©ments vectoriels structur√©s.
   *
   * Workflow :
   * 1. Capture screenshot du canvas
   * 2. Analyse via Claude Vision (d√©tection structures)
   * 3. Matching brush par bounding box
   * 4. Remplacement brush ‚Üí √©l√©ments vectoriels
   *
   * @param workspaceId Workspace ID
   * @param docId Document ID
   * @returns Statistiques de transformation
   */
  async transformBrushToVectorial(
    workspaceId: string,
    docId: string
  ): Promise<{
    brushDeleted: number;
    shapesCreated: number;
    connectorsCreated: number;
    mindmapsCreated: number;
  }> {
    // 1. Screenshot
    const screenshot = await fetch(
      `${this.affineClient.baseUrl}/workspaces/${workspaceId}/documents/${docId}/edgeless/screenshot`
    );
    const imageBuffer = await screenshot.arrayBuffer();

    // 2. Analyse IA
    const analysis = await this.claudeAPI.messages.create({
      model: "claude-3-5-sonnet-20241022",
      messages: [{
        role: "user",
        content: [
          {
            type: "image",
            source: {
              type: "base64",
              media_type: "image/png",
              data: Buffer.from(imageBuffer).toString('base64')
            }
          },
          {
            type: "text",
            text: `Analyse ce canvas dessin√© √† main lev√©e.

            Identifie les √©l√©ments structur√©s et retourne JSON :
            {
              "elements": [
                {"type": "shape", "shapeType": "rect", "bounds": [x, y, w, h], "text": "..."},
                {"type": "connector", "bounds": [x, y, w, h], "from": "...", "to": "..."},
                {"type": "mindmap", "bounds": [x, y, w, h], "root": "...", "branches": [...]}
              ]
            }`
          }
        ]
      })
    });

    const detected = JSON.parse(analysis.content[0].text);

    // 3. Transformation
    let stats = {
      brushDeleted: 0,
      shapesCreated: 0,
      connectorsCreated: 0,
      mindmapsCreated: 0
    };

    for (const element of detected.elements) {
      const [x, y, w, h] = element.bounds;

      // Matcher brush
      const matchingBrush = await this.affineClient.matchBrushByBoundingBox(
        workspaceId,
        docId,
        { x, y, width: w, height: h }
      );

      // Cr√©er √©l√©ment vectoriel
      await this.affineClient.createEdgelessElement(workspaceId, docId, {
        type: element.type,
        shapeType: element.shapeType,
        xywh: [x, y, w, h],
        text: element.text || element.root
      });

      // Supprimer brush
      for (const brush of matchingBrush) {
        await this.affineClient.deleteEdgelessElement(workspaceId, docId, brush.id);
        stats.brushDeleted++;
      }

      // Stats
      if (element.type === 'shape') stats.shapesCreated++;
      if (element.type === 'connector') stats.connectorsCreated++;
      if (element.type === 'mindmap') stats.mindmapsCreated++;
    }

    return stats;
  }
}
```

---

## 5. Exigences Techniques

### 5.1 Modifications Code

#### 5.1.1 TypeScript Types

**Fichier** : `src/client/types/edgeless.ts`

**Changements** :
```typescript
// Ligne 12 : Ajouter 'brush' dans le type union
export type EdgelessElementType =
  'connector' | 'shape' | 'text' | 'group' | 'mindmap' | 'brush'; // ‚Üê Ajout

// Ligne 306+ : Ajouter interface BrushElement
export interface BrushElement extends BaseElement {
  type: 'brush';
  xywh: number[] | string;
  rotate: number;
  points: number[][];
  lineWidth: number;
  color: string | { dark: string; light: string };
}

// Ligne 195 : Ajouter dans union type
export type EdgelessElement =
  | ConnectorElement
  | ShapeElement
  | TextElement
  | GroupElement
  | MindmapElement
  | BrushElement; // ‚Üê Ajout

// Ligne 235+ : Ajouter input type
export interface CreateBrushInput {
  points: number[][];
  lineWidth?: number;
  color?: string | { dark: string; light: string };
  xywh?: number[];
  rotate?: number;
}

// Ligne 258 : Ajouter dans union input
export type CreateElementInput =
  | ({ type: 'connector' } & CreateConnectorInput)
  | ({ type: 'shape' } & CreateShapeInput)
  | ({ type: 'text' } & CreateTextInput)
  | ({ type: 'group' } & CreateGroupInput)
  | ({ type: 'mindmap' } & CreateMindmapInput)
  | ({ type: 'brush' } & CreateBrushInput); // ‚Üê Ajout
```

#### 5.1.2 Element Defaults

**Fichier** : `src/client/runtime/element-defaults.ts`

**Changements** :
```typescript
// Ligne 142+ : Ajouter defaults brush
export const BRUSH_DEFAULTS = {
  rotate: 0,
  xywh: '[0,0,100,100]',
  lineWidth: 4,
  color: { dark: '#ffffff', light: '#000000' },
  points: [] as number[][],
};

// Ligne 158 : Modifier fonction applyElementDefaults
export function applyElementDefaults(
  elementData: Partial<CreateElementInput>
): Record<string, unknown> {
  const { type } = elementData;
  let defaults: Record<string, unknown> = {};

  switch (type) {
    case 'shape':
      defaults = { ...SHAPE_DEFAULTS };
      break;
    case 'connector':
      defaults = { ...CONNECTOR_DEFAULTS };
      break;
    case 'text':
      defaults = { ...TEXT_DEFAULTS };
      break;
    case 'group':
      defaults = { ...GROUP_DEFAULTS };
      break;
    case 'mindmap':
      defaults = { ...MINDMAP_DEFAULTS };
      break;
    case 'brush': // ‚Üê NOUVEAU
      defaults = { ...BRUSH_DEFAULTS };

      // Calculer xywh depuis points si non fourni
      if (!elementData.xywh && Array.isArray(elementData.points) && elementData.points.length > 0) {
        const points = elementData.points as number[][];
        const xs = points.map(p => p[0]);
        const ys = points.map(p => p[1]);
        const minX = Math.min(...xs);
        const minY = Math.min(...ys);
        const maxX = Math.max(...xs);
        const maxY = Math.max(...ys);
        defaults.xywh = `[${minX},${minY},${maxX - minX},${maxY - minY}]`;
      }
      break;
    default:
      throw new Error(`Unknown element type: ${type}`);
  }

  return {
    ...defaults,
    ...elementData,
  };
}
```

#### 5.1.3 Client Helpers (Brush Operations)

**Fichier** : `src/client/runtime/affine-client.ts`

**M√©thodes √† ajouter** (ligne ~2100) :

**A. Helper Highlight Brush** ‚≠ê NOUVEAU
```typescript
/**
 * Change la couleur d'un ou plusieurs brush pour feedback visuel.
 * Support presets : 'analyzing', 'processed', 'target', 'ignore'
 *
 * @param workspaceId Workspace ID
 * @param docId Document ID
 * @param brushIds Array of brush element IDs
 * @param colorPreset Color preset or custom hex color
 * @returns Promise resolving when all brush are updated
 */
async highlightBrush(
  workspaceId: string,
  docId: string,
  brushIds: string[],
  colorPreset: 'analyzing' | 'processed' | 'target' | 'ignore' | string
): Promise<void> {
  const colorMap: Record<string, string> = {
    analyzing: '#FFD700',  // Jaune
    processed: '#00FF00',  // Vert
    target: '#FF0000',     // Rouge
    ignore: '#808080'      // Gris
  };

  const color = colorMap[colorPreset] || colorPreset;
  const colorObj = { dark: color, light: color };

  // Batch update pour performance
  await Promise.all(
    brushIds.map(id =>
      this.updateEdgelessElement(workspaceId, docId, id, { color: colorObj })
    )
  );
}
```

**B. Helper Bounding Box Matching**
```typescript
/**
 * Find brush elements that overlap with a target bounding box.
 * Used for AI-driven brush ‚Üí vectorial transformation.
 *
 * @param workspaceId Workspace ID
 * @param docId Document ID
 * @param targetBox Target bounding box {x, y, width, height}
 * @param overlapThreshold Minimum overlap ratio (0-1, default: 0.3)
 * @returns Array of brush elements overlapping the target box
 */
async matchBrushByBoundingBox(
  workspaceId: string,
  docId: string,
  targetBox: { x: number; y: number; width: number; height: number },
  overlapThreshold = 0.3
): Promise<Array<Record<string, unknown>>> {
  await this.joinWorkspace(workspaceId);

  // Get all edgeless elements
  const allElements = await this.getEdgelessElements(workspaceId, docId);

  // Filter brush elements
  const brushElements = allElements.filter(el => el.type === 'brush');

  // Match by bounding box overlap
  const matching: Array<Record<string, unknown>> = [];

  for (const brush of brushElements) {
    const brushBox = this.parseBoundingBox(brush.xywh as string | number[]);
    const overlap = this.calculateOverlap(brushBox, targetBox);

    if (overlap >= overlapThreshold) {
      matching.push(brush);
    }
  }

  return matching;
}

/**
 * Parse bounding box from xywh (string or array).
 */
private parseBoundingBox(xywh: string | number[]): { x: number; y: number; width: number; height: number } {
  const arr = typeof xywh === 'string' ? JSON.parse(xywh) : xywh;
  return { x: arr[0], y: arr[1], width: arr[2], height: arr[3] };
}

/**
 * Calculate overlap ratio between two bounding boxes (Jaccard index).
 */
private calculateOverlap(
  box1: { x: number; y: number; width: number; height: number },
  box2: { x: number; y: number; width: number; height: number }
): number {
  const x1 = Math.max(box1.x, box2.x);
  const y1 = Math.max(box1.y, box2.y);
  const x2 = Math.min(box1.x + box1.width, box2.x + box2.width);
  const y2 = Math.min(box1.y + box1.height, box2.y + box2.height);

  if (x2 <= x1 || y2 <= y1) {
    return 0; // No overlap
  }

  const intersectionArea = (x2 - x1) * (y2 - y1);
  const box1Area = box1.width * box1.height;
  const box2Area = box2.width * box2.height;
  const unionArea = box1Area + box2Area - intersectionArea;

  return intersectionArea / unionArea; // Jaccard index
}
```

#### 5.1.4 REST Endpoint (Screenshot)

**Fichier** : `src/service/server.ts`

**Endpoint √† ajouter** (ligne ~1700) :
```typescript
app.get(
  '/workspaces/:workspaceId/documents/:docId/edgeless/screenshot',
  async (request, reply) => {
    const { workspaceId, docId } = request.params as {
      workspaceId: string;
      docId: string;
    };
    const query = request.query as {
      width?: string;
      height?: string;
      format?: 'png' | 'jpeg';
      quality?: string;
      viewport?: string;
    };

    const width = parseInt(query.width || '1920');
    const height = parseInt(query.height || '1080');
    const format = query.format || 'png';
    const quality = parseInt(query.quality || '90');

    try {
      const screenshot = await captureEdgelessCanvas(workspaceId, docId, {
        width,
        height,
        format,
        quality
      });

      reply
        .type(`image/${format}`)
        .send(screenshot);
    } catch (error) {
      reply.code(500).send({
        error: 'Failed to capture canvas screenshot',
        message: error instanceof Error ? error.message : 'Unknown error'
      });
    }
  }
);
```

**Helper Function** (playwright-based) :
```typescript
import { chromium } from 'playwright';

async function captureEdgelessCanvas(
  workspaceId: string,
  docId: string,
  options: {
    width: number;
    height: number;
    format: 'png' | 'jpeg';
    quality: number;
  }
): Promise<Buffer> {
  const browser = await chromium.launch({
    headless: true,
    args: ['--no-sandbox', '--disable-setuid-sandbox']
  });

  const page = await browser.newPage({
    viewport: { width: options.width, height: options.height }
  });

  // Navigate to edgeless mode
  const url = `${process.env.AFFINE_BASE_URL}/workspace/${workspaceId}/${docId}?mode=edgeless`;
  await page.goto(url, { waitUntil: 'networkidle' });

  // Wait for canvas to render
  await page.waitForSelector('.affine-edgeless-surface', { timeout: 10000 });

  // Capture screenshot
  const screenshot = await page.screenshot({
    type: options.format,
    quality: options.format === 'jpeg' ? options.quality : undefined,
    fullPage: false
  });

  await browser.close();

  return Buffer.from(screenshot);
}
```

### 5.2 D√©pendances √† Ajouter

**Fichier** : `package.json`

```json
{
  "dependencies": {
    "playwright": "^1.40.0"
  }
}
```

**Installation** :
```bash
npm install playwright
npx playwright install chromium
```

### 5.3 Configuration D√©ploiement

**Dockerfile** : Ajouter support Playwright

```dockerfile
FROM node:20-slim AS build
WORKDIR /app

# Install Playwright dependencies
RUN apt-get update && apt-get install -y \
    libnss3 \
    libatk1.0-0 \
    libatk-bridge2.0-0 \
    libcups2 \
    libdrm2 \
    libxkbcommon0 \
    libxcomposite1 \
    libxdamage1 \
    libxfixes3 \
    libxrandr2 \
    libgbm1 \
    libasound2 \
    && rm -rf /var/lib/apt/lists/*

COPY package*.json ./
RUN npm ci
COPY . .
RUN npm run build

FROM node:20-slim AS runtime
ENV NODE_ENV=production
WORKDIR /app

# Install Playwright dependencies (runtime)
RUN apt-get update && apt-get install -y \
    libnss3 libatk1.0-0 libatk-bridge2.0-0 libcups2 \
    && rm -rf /var/lib/apt/lists/*

COPY package*.json ./
RUN npm ci --omit=dev
RUN npx playwright install chromium --with-deps
COPY --from=build /app/dist ./dist
EXPOSE 3000
CMD ["node", "dist/service/start.js"]
```

---

## 6. Roadmap & Priorisation

### 6.1 Phase 1 : Brush CRUD + Highlight (Priorit√© Haute)

**Objectif** : Support complet cr√©ation/modification brush elements + feedback visuel pour LLM

**Effort** : 3-4 heures

**Livrables** :
1. ‚úÖ Type `BrushElement` dans `edgeless.ts`
2. ‚úÖ Defaults `BRUSH_DEFAULTS` dans `element-defaults.ts`
3. ‚úÖ Case `'brush'` dans `applyElementDefaults()`
4. ‚úÖ M√©thode `highlightBrush()` dans `affine-client.ts` ‚≠ê NOUVEAU
5. ‚úÖ Tests unitaires `tests/unit/brush-elements.test.ts` (incluant highlight tests)
6. ‚úÖ Smoke test `scripts/run-brush-api-smoke.ts`
7. ‚úÖ Documentation README mise √† jour

**Validation** :
```bash
# Test cr√©ation brush via API
curl -X POST "https://affine-api.robotsinlove.be/workspaces/ABC/documents/XYZ/edgeless/elements" \
  -H "Content-Type: application/json" \
  -d '{
    "type": "brush",
    "points": [[100,100,0.5], [200,200,0.8]],
    "lineWidth": 6
  }'
# ‚Üí Retour 201 avec ID
```

### 6.2 Phase 2 : Canvas Screenshot (Priorit√© Moyenne)

**Objectif** : Endpoint pour capturer image du canvas

**Effort** : 1-2 jours

**Livrables** :
1. ‚úÖ Endpoint `GET /edgeless/screenshot`
2. ‚úÖ Helper `captureEdgelessCanvas()` avec Playwright
3. ‚úÖ Support query params (width, height, format, quality)
4. ‚úÖ Tests unitaires `tests/unit/canvas-screenshot.test.ts`
5. ‚úÖ Smoke test `scripts/run-screenshot-smoke.ts`
6. ‚úÖ Dockerfile mis √† jour (Playwright dependencies)

**Validation** :
```bash
# Capturer screenshot
curl "https://affine-api.robotsinlove.be/workspaces/ABC/documents/XYZ/edgeless/screenshot" \
  -o canvas.png
# ‚Üí Fichier canvas.png cr√©√© (taille > 10KB)

# V√©rifier image valide
file canvas.png
# ‚Üí canvas.png: PNG image data, 1920 x 1080, ...
```

### 6.3 Phase 3 : Transformation Assist√©e (Priorit√© Basse)

**Objectif** : Helpers pour workflow Brush ‚Üí Vectoriel

**Effort** : 1 jour

**Livrables** :
1. ‚úÖ M√©thode `matchBrushByBoundingBox()` dans `affine-client.ts`
2. ‚úÖ Documentation exemple `src/noemai/brush-transformer.ts` (r√©f√©rence)
3. ‚úÖ Tests unitaires `tests/unit/brush-matching.test.ts`
4. ‚úÖ Guide d'int√©gration NoemAI dans `docs/noemai-integration-guide.md`

**Validation** :
```typescript
// Test matching bounding box
const matchingBrush = await client.matchBrushByBoundingBox(
  workspaceId,
  docId,
  { x: 100, y: 100, width: 200, height: 150 }
);
console.log(`Found ${matchingBrush.length} brush elements`);
// ‚Üí Found 3 brush elements
```

### 6.4 Timeline Global

| Phase | Effort | D√©but | Fin | Status |
|-------|--------|-------|-----|--------|
| Phase 1 : Brush CRUD + Highlight | 3-4h | Semaine 1 | Semaine 1 | üî≤ Todo |
| Phase 2 : Screenshot API Multi-Mode | 1-2 jours | Semaine 1 | Semaine 1 | üî≤ Todo |
| Phase 3 : Helpers | 1 jour | Semaine 2 | Semaine 2 | üî≤ Todo |
| Documentation | 0.5 jour | Semaine 2 | Semaine 2 | üî≤ Todo |
| **Total** | **~4 jours** | | | |

---

## 7. Tests & Validation

### 7.1 Test Strategy

**Niveaux de tests** :
1. **Unit tests** : Tests isol√©s des fonctions helpers
2. **Integration tests** : Tests end-to-end API REST
3. **Smoke tests** : Sc√©narios r√©els sur workspace `Tests`

### 7.2 Test Coverage Target

- ‚úÖ Unit tests : **> 80%** coverage
- ‚úÖ Integration tests : **100%** des endpoints
- ‚úÖ Smoke tests : **1 sc√©nario complet** par feature

### 7.3 Test Documents

**Workspace** : `Tests` (ID: `65581777-b884-4a3c-af69-f286827e90b0`)
**Folder** : `API Test Folder` (ID: `gMd6IfCCR1mPSErqj3vGj`)

**Documents de test** :
1. `Test-SketchAPI` (existant) : 5184 brush elements
2. `Test-BrushCRUD` (√† cr√©er) : Test cr√©ation/modification/suppression
3. `Test-Screenshot` (√† cr√©er) : Test capture canvas
4. `Test-Transformation` (√† cr√©er) : Test workflow Brush ‚Üí Vectoriel

---

## 8. Documentation

### 8.1 Documentation Utilisateur

**Fichier** : `README.md` (section √† ajouter)

**Contenu** :
```markdown
## üé® Brush Elements API

AFFiNE brush elements represent freehand ink strokes captured by stylus/touch input.

### Create Brush Element

```bash
POST /workspaces/:workspaceId/documents/:docId/edgeless/elements
```

**Payload**:
```json
{
  "type": "brush",
  "points": [[x, y, pressure], ...],
  "lineWidth": 4,
  "color": {"dark": "#fff", "light": "#000"}
}
```

### Capture Canvas Screenshot

```bash
GET /workspaces/:workspaceId/documents/:docId/edgeless/screenshot?width=1920&height=1080&format=png
```

Returns PNG/JPEG image of the canvas.

### Transformation Pattern (NoemAI)

See `docs/noemai-integration-guide.md` for complete workflow:
1. User draws freehand (brush elements created automatically)
2. AI captures screenshot and analyzes structure
3. AI matches brush by bounding box
4. AI replaces brush with vectorial elements (shapes, connectors, mindmaps)
```

### 8.2 Documentation Technique

**Fichiers √† cr√©er** :

1. **`docs/noemai-integration-guide.md`** : Guide complet int√©gration NoemAI
   - Architecture overview
   - Workflow d√©taill√© Brush ‚Üí Vectoriel
   - Exemples de code avec Claude Vision
   - Best practices

2. **`docs/brush-api-reference.md`** : R√©f√©rence compl√®te API Brush
   - Format JSON d√©taill√©
   - Tous les endpoints (CRUD)
   - Propri√©t√©s et validations
   - Exemples cURL

3. **`docs/screenshot-api-reference.md`** : R√©f√©rence API Screenshot
   - Query parameters
   - Formats support√©s
   - Configuration Playwright
   - Troubleshooting

### 8.3 Code Documentation

**Ajouter JSDoc** sur toutes les m√©thodes publiques :

```typescript
/**
 * Create a brush element (freehand ink stroke).
 *
 * @param workspaceId - Workspace UUID
 * @param docId - Document UUID
 * @param brushData - Brush properties
 * @param brushData.points - Array of [x, y, pressure] coordinates (min 2 points)
 * @param brushData.lineWidth - Stroke width in pixels (default: 4)
 * @param brushData.color - Stroke color (theme-aware)
 * @returns Created brush element with generated ID
 *
 * @example
 * ```typescript
 * const brush = await client.createEdgelessElement(workspaceId, docId, {
 *   type: 'brush',
 *   points: [[100, 100, 0.5], [200, 200, 0.8]],
 *   lineWidth: 6,
 *   color: { dark: '#ff0000', light: '#ff0000' }
 * });
 * ```
 */
async createEdgelessElement(/* ... */) { /* ... */ }
```

---

## 9. Risques & Mitigation

| Risque | Impact | Probabilit√© | Mitigation |
|--------|--------|-------------|------------|
| Playwright performance (lent) | Moyen | √âlev√©e | Cache screenshots, optimiser viewport, limiter rate |
| Playwright d√©ploiement (complexit√©) | √âlev√© | Moyenne | Dockerfile test√©, documentation compl√®te, fallback sans screenshot |
| Bounding box matching impr√©cis | Moyen | Moyenne | Threshold configurable, am√©liorer avec algo vectoriel si besoin |
| Changements schema AFFiNE | √âlev√© | Faible | Tests d'int√©gration r√©guliers, monitoring version AFFiNE |
| Co√ªt API Claude Vision | Moyen | Moyenne | Batch screenshots, cache analyses, pricing monitoring |

**Plan de Contingence** :
- Si Playwright trop lent ‚Üí Impl√©menter cache intelligent (TTL 30s)
- Si matching impr√©cis ‚Üí Ajouter fallback analyse vectorielle (Phase 2)
- Si API Claude co√ªteuse ‚Üí Impl√©menter rate limiting utilisateur

---

## 10. M√©triques de Succ√®s

### 10.1 M√©triques Techniques

| M√©trique | Objectif | Mesure |
|----------|----------|--------|
| Temps de r√©ponse POST brush | < 500ms | Monitoring Fastify |
| Temps de capture screenshot | < 3s | Monitoring endpoint |
| Coverage tests | > 80% | Vitest report |
| Zero breaking changes | 100% | Tests de r√©gression |

### 10.2 M√©triques Business (NoemAI)

| M√©trique | Objectif | Mesure |
|----------|----------|--------|
| Time-to-market NoemAI | -40% (vs client custom) | Timeline projet |
| Support multi-devices | 100% (Onyx, iPad, Surface, Desktop) | Tests hardware |
| Pr√©cision transformation Brush ‚Üí Vectoriel | > 85% | User testing |
| Adoption NoemAI | > 10 utilisateurs beta | Analytics |

---

## 11. Annexes

### 11.1 R√©f√©rences

- **Gap Analysis NoemAI** : Session 2025-01-19 (r√©sultats dans ce PRD)
- **Document Test Brush** : `Tests/API Test Folder/Test-SketchAPI` (5184 brush)
- **AFFiNE BlockSuite Source** : https://github.com/toeverything/blocksuite
- **Claude Vision API** : https://docs.anthropic.com/claude/docs/vision

### 11.2 Contacts

- **Product Owner** : Gilles Pinault
- **Developer** : Claude Code (AI Assistant)
- **Workspace AFFiNE** : https://affine.robotsinlove.be
- **Projet NoemAI** : Documentation fournie (Vision v4.1)

### 11.3 Changelog

| Version | Date | Auteur | Changements |
|---------|------|--------|-------------|
| 1.0 | 2025-01-19 | Claude Code | Cr√©ation initiale bas√©e sur gap analysis |
| 1.1 | 2025-01-19 | Claude Code | Ajout approche progressive multi-r√©solution (fit-all/viewport/region) |
| 1.2 | 2025-01-19 | Claude Code | Ajout fonctionnalit√© highlight_brush pour feedback visuel LLM |

---

**Status** : ‚úÖ PRD Complet v1.2 - Pr√™t pour impl√©mentation

**Prochaines Actions** :
1. Review PRD avec Product Owner
2. Validation priorit√©s (Phase 1 en premier ?)
3. Setup environnement de d√©veloppement
4. Impl√©mentation Phase 1 (Brush CRUD + Highlight)
